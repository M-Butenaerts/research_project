{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: preprocessing not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: preprocessing not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\denys\\Programming\\BEP\\Grammar\\HerbExamples.jl\\notebooks\\grammar.ipynb:3"
     ]
    }
   ],
   "source": [
    "using ScikitLearn\n",
    "using ScikitLearn.Pipelines: Pipeline, FeatureUnion\n",
    "using ScikitLearn.preprocessing : FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.Herb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Revise\n",
    "\n",
    "include(\"../../Herb.jl/src/Herb.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1: Start = Pipeline([PRE, EST])\n",
       "2: PRE = PASS\n",
       "3: PRE = TFM\n",
       "4: PRE = EST\n",
       "5: PRE = Pipeline([PRE, PRE])\n",
       "6: PRE = FeatureUnion([PRE, PRE])\n",
       "7: EST = (\"linear_pca\", PCA())\n",
       "8: EST = (\"kernel_pca\", KernelPCA())\n",
       "9: TFM = ()\n",
       "10: PASS = (\"id\", FunctionTransformer((x->begin\n",
       "                \u001b[90m#= c:\\Users\\denys\\Programming\\BEP\\Grammar\\HerbExamples.jl\\notebooks\\grammar.ipynb:9 =#\u001b[39m\n",
       "                x\n",
       "            end)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need to import:\n",
    "# FeatureUnion\n",
    "\n",
    "g = Herb.HerbGrammar.@cfgrammar begin\n",
    "    Start = Pipeline([PRE, EST]) \n",
    "    PRE   = PASS | TFM | EST | Pipeline([PRE, PRE]) | FeatureUnion([PRE, PRE])\n",
    "    EST   = (\"linear_pca\", PCA()) | (\"kernel_pca\", KernelPCA())\n",
    "    TFM   = () \n",
    "    PASS  = (\"id\", FunctionTransformer(x -> x))     # this transformer leaves the input unchanged\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1: START = EST\n",
       "2: START = sequence(PRE, CLASSIF)\n",
       "3: PRE = PREPROC\n",
       "4: PRE = FSELECT\n",
       "5: PRE = sequence(PRE, PRE)\n",
       "6: PRE = parallel(PRE, PRE)\n",
       "7: PREPROC = (\"StandardScaler\", StandardScaler)\n",
       "8: PREPROC = (\"RobustScaler\", RobustScaler)\n",
       "9: PREPROC = (\"MinMaxScaler\", MinMaxScaler)\n",
       "10: PREPROC = (\"MaxAbsScaler\", MaxAbsScaler)\n",
       "11: PREPROC = (\"RandomizedPCA\", RandomizedPCA)\n",
       "12: PREPROC = (\"Binarizer\", Binarizer)\n",
       "13: PREPROC = (\"PolynomialFeatures\", PolynomialFeatures)\n",
       "14: CLASSIF = (\"DecisionTree\", DecisionTree)\n",
       "15: CLASSIF = (\"RandomForest\", RandomForest)\n",
       "16: CLASSIF = (\"eXtreme Gradient Boosting Classifier\", eXtremeGradientBoostingClassifier)\n",
       "17: CLASSIF = (\"LogisticRegression\", LogisticRegression)\n",
       "18: CLASSIF = (\"KNearestNeighborClassifier\", KNearestNeighborClassifier)\n",
       "19: FSELECT = (\"VarianceThreshold\", VarianceThreshold)\n",
       "20: FSELECT = (\"SelectKBest\", SelectKBest)\n",
       "21: FSELECT = (\"SelectPercentile\", SelectPercentile)\n",
       "22: FSELECT = (\"SelectFwe\", SelectFwe)\n",
       "23: FSELECT = (\"Recursive Feature Elimination (RFE)\", RecursiveFeatureElimination)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequence(a, b) = Pipeline([a, b]) \n",
    "parallel(a, b) = FeatureUnion([a, b]) \n",
    "# idTrans = FunctionTransformer(x -> x)\n",
    "# The code becomes a lot cleaner when you take out the PASS option. \n",
    "# We should probably look into splitting up the estimators in different categories and adding a classifier category\n",
    "\n",
    "g = Herb.HerbGrammar.@cfgrammar begin\n",
    "    START   = CLASSIF | sequence(PRE, CLASSIF)\n",
    "    PRE     = PREPROC | FSELECT | sequence(PRE, PRE) | parallel(BRANCH, BRANCH)\n",
    "    BRANCH  = PRE | CLASSIF | sequence(PRE, CLASSIF) \n",
    "\n",
    "    PREPROC =   \n",
    "        (\"StandardScaler\", StandardScaler) |\n",
    "        (\"RobustScaler\", RobustScaler) |\n",
    "        (\"MinMaxScaler\", MinMaxScaler) |\n",
    "        (\"MaxAbsScaler\", MaxAbsScaler) |\n",
    "        (\"RandomizedPCA\", RandomizedPCA) |\n",
    "        (\"Binarizer\", Binarizer) |\n",
    "        (\"PolynomialFeatures\", PolynomialFeatures)\n",
    "    FSELECT =  \n",
    "        (\"VarianceThreshold\", VarianceThreshold) |\n",
    "        (\"SelectKBest\",  SelectKBest) |\n",
    "        (\"SelectPercentile\",  SelectPercentile) |\n",
    "        (\"SelectFwe\",  SelectFwe) |\n",
    "        (\"Recursive Feature Elimination\",  RFE) \n",
    "    CLASSIF =\n",
    "        (\"DecisionTree\", DecisionTree) |\n",
    "        (\"RandomForest\", RandomForest) |\n",
    "        (\"Gradient Boosting Classifier\", GradientBoostingClassifier) |\n",
    "        (\"LogisticRegression\", LogisticRegression) |\n",
    "        (\"KNearestNeighborClassifier\", KNearestNeighborClassifier)\n",
    "\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
